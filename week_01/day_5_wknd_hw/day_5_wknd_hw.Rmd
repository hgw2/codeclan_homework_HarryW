---
title: "R Notebook"
output: html_notebook
---

# Packages
```{r}
library(tidyverse)
library(janitor)
```


# Load in data

```{r}
books <- read_csv("data/books.csv")
```
```{r}
head(books)
```

```{r}
names(books)
```

There are some columns which I do not think will not useful so, I am going to drop bookID, isbn, isbn13 and publication_date.

```{r}
dim(books)
```

There are a total of 8472 books in the dataset. 

```{r}
books_subset <- books %>%
  select(-bookID, -isbn, -isbn13, -publication_date)

head(books_subset)
```

## Check for NAs

```{r}
books_subset %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```

I will also check if there are any columns that are 0. 

```{r}
books_subset %>%
  mutate(across(where(is.numeric), ~ if_else(.x == 0, TRUE, FALSE))) %>%
  select(is.logical) %>%
  summarise(across(.fns = ~ sum(.x, na.rm = TRUE)))
```

You clearly cannot have a book with 0 pages so I will replace that with an NA value and impute it later. I will also do the same with the other variables 

```{r}
books_nul_removed <- books_subset %>%
  mutate(across(where(is.numeric), ~ na_if(.x, 0)))

# Check no. of NA values
books_nul_removed %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```

For any of the NAs in author, language code and publisher I will replace with unavailable.

```{r}
books_cleaned <- books_nul_removed %>%
  mutate(
    authors = coalesce(authors, "unavailable"),
    language_code = coalesce(language_code, "unavailable"),
    publisher = coalesce(publisher, "unavailable")
  )
```

For average_rating and num_pages I am going to impute the median for those values.

```{r}
books_cleaned <- books_cleaned %>%
  mutate(
    average_rating =
      coalesce(average_rating, median(average_rating, na.rm = TRUE)),
    num_pages =
      coalesce(num_pages, median(num_pages, na.rm = TRUE))
  )


books_cleaned %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```
Finally for ratings_count and text_reviews_count, you the ratings count being 0 and an average rating so I will impute this with the median value and then replace text_review_count with 0

```{r}
books_cleaned <- books_cleaned %>%
  mutate(
    ratings_count = coalesce(ratings_count, median(ratings_count, na.rm = TRUE)),
    text_reviews_count = coalesce(text_reviews_count, 0)
  )
```

```{r}
books_cleaned %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```
# Combine review counts

I am going to combine the ratings_count and the text_reviews_count into one column

```{r}
books_cleaned <- books_cleaned %>%
  mutate(total_reviews = ratings_count + text_reviews_count) %>%
  select(-ratings_count, -text_reviews_count)
```


# Recoding language_code
Looking at the head of the table I can see that there are at least two languages for English. I will explore this further

```{r}
books_cleaned %>%
  distinct(language_code) %>%
  arrange(language_code)
```
There are a 2 numerical values so I will replace them with unavailable 

```{r}
books_cleaned <- books_cleaned %>%
  mutate(language_code = recode(language_code,
    "9780674842113" = "unavailable",
    "9780851742717" = "unavailable"
  ))
```

I am going to change all the english codes to english, enm to middle_english and all the foreign languages into foreign_language

```{r}
books_cleaned_lang <- books_cleaned %>%
  mutate(
    language_code = recode(language_code,
                           "en-CA"       = "english",
                           "en-GB"       = "english",
                           "en-US"       = "english",
                           "eng"         = "english",
                           "enm"         = "middle_english",
                           "unavailable" = "unavailable",
                           .default      = "foreign_language"
    )
  )
```

As we are no longer using language codes I am changing the name of the column to language.

```{r}
books_cleaned_lang <- books_cleaned_lang %>%
  rename(language = language_code)
```

Lets count to see how many we have in each language.

```{r}
books_cleaned_lang %>%
  group_by(language) %>%
  summarise(count = n())
```

Seeing as I can't speak any foreign languages I am going to drop the foreign_language and unavailable books.  

```{r}
eng_books <- books_cleaned_lang %>%
  filter(language == "middle_english" | language == "english")
```

# Clean publishers

```{r}
eng_books %>%
  distinct(publisher) %>%
  arrange(publisher)
```

There are a total of 1,750 publishers listed but there are written in different ways for example, there there are a number of different ACE publishers listed. I struggled to find a way that would identify potential duplicates, without working my way through the list and changing them individually. 
```{r}
eng_books %>%
  group_by(publisher) %>%
  summarise(count = n()) %>%
  arrange(publisher)
```

Seeing as we are only talking about 1 or 2 books this shouldn't be too much  are a lot of small publishers I am going to replace these names with anything under 15 books with Small Publisher.

# Create publisher count column 

```{r}
books_pub_count <- eng_books %>%
  group_by(publisher) %>%
  mutate(publisher_count = n()) %>%
  ungroup()
```

Change the publishers with a count of < 15 to Small Publisher 

```{r}
books_cleaned_pub <- books_pub_count %>%
  mutate(
    publisher = case_when(
      publisher_count < 15 ~ "Small Publisher",
      TRUE ~ publisher
    )
  ) %>%
  select(-publisher_count)
```

Check publisher count 

```{r}
books_cleaned_pub %>%
  group_by(publisher) %>%
  summarise(count = n()) %>%
  arrange(desc(count))
```

# Top 10 Best Rated Books, Authors and Publishers

I will list the top 10 rated books, the top 10 rated authors and the top 10 rated publishers

```{r}
books_cleaned_pub %>%
  select(title, average_rating, total_reviews) %>%
  arrange(desc(average_rating)) %>%
  head(10)
```

It seems here that books with a high average_rating but a low ratings count has skewed the top 10 list so I am going to create a new variable called total_score which will be average_rating*ratings count.
```{r}
books_total_scores <- books_cleaned_pub %>%
  mutate(total_score = average_rating * total_reviews)
```

### Top 10 Books
```{r}
books_total_scores %>%
  select(title, total_score) %>%
  arrange(desc(total_score)) %>%
  head(10)
```


### Top 10 Authors
```{r}
books_total_scores %>%
  group_by(authors) %>%
  summarise(avg_total_score = mean(total_score)) %>%
  slice_max(avg_total_score, n = 10)
```

### Top 10 publishers
```{r}
books_total_scores %>%
  group_by(publisher) %>%
  summarise(avg_total_score = mean(total_score)) %>%
  slice_max(avg_total_score, n = 10)
```

# Read Times
It takes the average person approximate 2-5 minutes to read a page in a book. I will use page number to give an estimate on how long it will take to read each book. I will multiple the num_page by 3 and divideby 60 to give the time in hours

```{r}
read_time_book <- books_total_scores %>%
  mutate(estimated_read_time = (num_pages * 3) / 60)
read_time_book
```

# Quick reads 

```{r}
read_time_book %>%
  select(title, num_pages) %>%
  arrange(num_pages) %>%
  head(10)
```

```{r}
read_time_book %>%
  select(title, estimated_read_time) %>%
  arrange(estimated_read_time) %>%
  head(10)
```

There is obviously some errors in the data as LOTR the Return of the King is not a page long! I am going to use this anyway and categorize anything under 10 hours as a quick read, anything under 50 hours as a long read and anything over 30 hours as an epic read.

```{r}
read_categories <- read_time_book %>%
  mutate(
    time_category = case_when(
      estimated_read_time < 10 ~ "Quick Read",
      estimated_read_time < 50 ~ "Long Read",
      estimated_read_time >= 50 ~ "Epic Read"
    )
  )
```

Check to see how many books we have for each category.

```{r}
read_categories %>%
  group_by(time_category) %>%
  summarise(total = n())
```


# Top 10 in each read category 

## Top 10 quick reads
```{r}
read_categories %>%
  filter(time_category == "Quick Read") %>%
  select(title, total_score) %>%
  arrange(desc(total_score)) %>%
  head(10)
```


## Top 10 long reads
```{r}
read_categories %>%
  filter(time_category == "Long Read") %>%
  select(title, total_score) %>%
  arrange(desc(total_score)) %>%
  head(10)
```


## Top 10 Epic Reads
```{r}
read_categories %>%
  filter(time_category == "Epic Read") %>%
  select(title, total_score) %>%
  arrange(desc(total_score)) %>%
  head(10)
```


# Ratings category

I will create a ratings category where 2 million as a must own. Between 2 million and 500,000 a nice to have. between 500,000 and 100,000 a library filler and under 100,000 as avoid
 
```{r}
own_categories <- read_categories %>%
  mutate(
    own_category = case_when(
      total_score < 1e5 ~ "Avoid",
      total_score < 5e5 ~ "Library filler",
      total_score < 2e6 ~ "Nice to have",
      total_score >= 2e6 ~ "Must own"
    )
  )
```
```{r}
own_categories %>%
  group_by(own_category) %>%
  summarise(total = n())
```
 
# Random library generator 

Say we wanted to create a library of 200 books. It must contain all 62 of the must own books and the rest a random selection of the Nice to have books.
```{r}
must_own <- own_categories %>%
  filter(own_category == "Must own") %>%
  select(title, authors)

must_own
```

Random nice to have books 

```{r}
nice_to_have <- own_categories %>%
  filter(own_category == "Nice to have") %>%
  select(title, authors) %>%
  sample_n(size = 200 - nrow(must_own))

nice_to_have
```
```{r}
random_library <- rbind(must_own, nice_to_have) %>%
  arrange(title)

random_library
```

## Holiday reading list
Say I was going on holiday and wanted to select 5 books to take with me, they must be quick to read and enjoyable.

```{r}
holiday_books <- own_categories %>%
  filter(
    own_category == "Must own" | own_category == "Nice to have",
    time_category == "Quick Read"
  ) %>%
  sample_n(5) %>%
  select(title) %>%
  pull(title)

holiday_books
```
