---
title: "R Notebook"
output: html_notebook
---

#Packages
```{r}
library(tidyverse)
library(janitor)
```


#Load in data
```{r}
books <- read_csv("data/books.csv")
```
```{r}
books
```



```{r}
names(books)

dim(books)
```
I am going to drop bookID, isbn, isbn13 and publication_date as I don't think these will be necessary.

```{r}
books_subset <- books %>%
  select(-bookID, -isbn, -isbn13, -publication_date)

head(books_subset)
```

##Check for NAs

```{r}
books_subset %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```

There are are also a few 0 values so lets see how many there are in each

```{r}
books_subset %>%
  mutate(across(where(is.numeric), ~ if_else( .x == 0, TRUE, FALSE))) %>% 
  select(is.logical) %>% 
  summarise(across(.fns = ~sum(.x, na.rm = TRUE)))

```
You clearly cannot have a book with 0 pages so I will replace that for now with an NA value and impute it later. I will also do the same with the other variables 

```{r}
books_nul_removed <-books_subset %>%
  mutate(across(where(is.numeric), ~ na_if(.x , 0)))

books_nul_removed %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```

There are not too many NAs but it will be good to deal with them. For any of the NAs in author, language code and publisher I will replace with unavailable.

```{r}
books_cleaned <- books_nul_removed %>%
  mutate(authors = coalesce(authors, "unavailable"),
         language_code = coalesce(language_code, "unavailable"),
         publisher = coalesce(publisher, "unavailable")
  )
  

```

For average_rating and num_pages I am going to impute the median for those values.

```{r}
books_cleaned <- books_cleaned %>%
  mutate(
    average_rating =
      coalesce(average_rating, median(average_rating, na.rm = TRUE)),
    num_pages =
      coalesce(num_pages, median(num_pages, na.rm = TRUE))
  )


books_cleaned %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```
Finally for ratings_count and text_reviews_count, you the ratings count being 0 and an average rating so I will impute this with the median value and then replace text_review_count with 0

```{r}
books_cleaned <- books_cleaned %>%
  mutate(ratings_count = coalesce(ratings_count, median(ratings_count, na.rm = TRUE)),
         text_reviews_count = coalesce(text_reviews_count, 0)
  )
```

```{r}
books_cleaned %>%
  summarise(across(.fns = ~ sum(is.na(.x))))
```
#Combine review counts

I am going to combine the ratings_count and the text_reviews_count into one column

```{r}
books_cleaned <- books_cleaned %>% 
  mutate(total_reviews = ratings_count + text_reviews_count) %>% 
  select(-ratings_count, -text_reviews_count)
```


#Recoding language_code
Looking at the head of the table I can see that there are at least two languages for English. I will explore this further

```{r}
books_cleaned %>% 
  distinct(language_code) %>%
  arrange(language_code)
```
There are a 2 numerical values so I will replace them with unavailable 

```{r}
books_cleaned <- books_cleaned %>% 
  mutate(language_code = recode(language_code, 
                                "9780674842113" = "unavailable",
                                "9780851742717" = "unavailable")
  )
```

I am going to change all the english codes to english, enm to middle_english and all the foreign languages into foreign_language

```{r}
books_cleaned_lang <- books_cleaned %>% 
  mutate(language_code = recode(language_code, 
                                "en-CA" = "english",
                                "en-GB" = "english",
                                "en-US" = "english",
                                "eng" = "english",
                                "enm" = "middle_english",
                                "unavailable" ="unavailable",
                                .default = "foreign_language"
                                )
  )
```

As we are no longer using language codes I am changing the name to language
```{r}
 books_cleaned_lang <- books_cleaned_lang %>% 
  rename(language = language_code)
```

Lets count to see how many we have in each language
```{r}
books_cleaned_lang %>% 
  group_by(language) %>% 
  summarise(count = n())
```

Seeing as I can't speak any foreign languages I am going to drop the foreign_language and unavailable books 
```{r}
eng_books <- books_cleaned_lang %>%  
  filter(language == "middle_english" | language == "english")
```

#Clean publishers
```{r}
eng_books %>% 
  distinct(publisher) %>% 
  arrange(publisher)
```



```{r}
eng_books %>% 
  group_by(publisher) %>% 
  summarise(count = n()) %>% 
  arrange(publisher)

```

There are clearly a number of publishers which are listed in different ways. It will be good to find a way to identify these but I cannot find anything for now. Howvever seeing as there are a lot of small publishers I am going to replace these names with anything under 15 books with Small Publisher.

Create publisher count column 

```{r}
books_pub_count <-eng_books %>% 
  group_by(publisher) %>% 
  mutate(publisher_count = n()) %>% 
  ungroup()
  
```

Change the publishers with a count of < 15 to Small Publisher 

```{r}
books_cleaned_pub <-books_pub_count %>% 
  mutate(
    publisher = case_when(
      publisher_count < 15 ~ "Small Publisher",
      TRUE                 ~ publisher
    )
  ) %>% 
  select(-publisher_count)
```



```{r}
books_cleaned_pub %>% 
  group_by(publisher) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
```

#Top 10 Best Rated Books, Authors and Publishers

I will list the top 10 rated books, the top 10 rated authors and the top 10 rated publishers

```{r}
books_cleaned_pub %>% 
  select(title, average_rating, total_reviews) %>% 
  arrange(desc(average_rating)) %>% 
  head(10)
```

It seems here that books with a high average_rating but a low ratings count has skewed the top 10 list so I am going to create a new variable called total_score which will be average_rating*ratings count.
```{r}
books_total_scores <- books_cleaned_pub %>% 
  mutate(total_score = average_rating * total_reviews)
```

Top 10 Books
```{r}
books_total_scores %>% 
  select(title, total_score) %>% 
  arrange(desc(total_score)) %>% 
  head(10)
```


Top 10 Authors
```{r}
books_total_scores %>% 
  group_by(authors) %>% 
  summarise(avg_total_score = mean(total_score)) %>% 
  slice_max(avg_total_score, n = 10)
```

Top 10 publishers
```{r}
books_total_scores %>% 
  group_by(publisher) %>% 
  summarise(avg_total_score = mean(total_score)) %>% 
  slice_max(avg_total_score, n = 10)
```

#Read Times
It takes the average person approximate 2-5 minutes to read a page in a book. I will use page number to give an estimate on how long it will take to read each book. I will multiple the num_page by 3 and divideby 60 to give the time in hours

```{r}
read_time_book <- books_total_scores %>% 
  mutate(estimated_read_time = (num_pages * 3)/ 60)
read_time_book
```

Quick reads 

```{r}
read_time_book %>% 
  select(title, num_pages) %>% 
  arrange(num_pages) %>% 
  head(10)
```

```{r}
read_time_book %>% 
  select(title, estimated_read_time) %>% 
  arrange(estimated_read_time) %>% 
  head(10)
```
There is obviously some errors in the data as LOTR the Return of the King is not a page long! I am going to use this anyway and categorize anything under 10 hours as a quick read, anything under 50 hours as a long read and anything over 30 hours as an epic read.

```{r}
read_categories <-read_time_book %>% 
  mutate(
    time_category = case_when(
      estimated_read_time < 10 ~ "Quick Read",
      estimated_read_time < 50 ~ "Long Read",
      estimated_read_time >= 50 ~ "Epic Read"
      )
  )
```

#Top 10 in each read category 

## Top 10 quick reads

```{r}
read_categories %>% 
  filter(time_category == "Quick Read") %>% 
  select(title, total_score) %>% 
  arrange(desc(total_score)) %>% 
  head(10)
```
## Top 10 long reads
```{r}
read_categories %>% 
  filter(time_category == "Long Read") %>% 
  select(title, total_score) %>% 
  arrange(desc(total_score)) %>% 
  head(10)
```

```{r}
read_categories %>% 
  filter(time_category == "Epic Read") %>% 
  select(title, total_score) %>% 
  arrange(desc(total_score)) %>% 
  head(10)
```


#Ratings category

#Random library generator 